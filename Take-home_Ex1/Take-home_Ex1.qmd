---
title: "Take-home_Ex1"
editor: visual
author: Jia Jian
date: 03 December 2023
---

# Take-home Exercise 1: Geospatial Analytics for Public Good

## Background

As city-wide urban infrastructures such as buses, taxis, MRT, public utilities and roads digitalize more, the datasets obtained can be used as a framework for tracking movement patterns through space and time. This is particularly true with the recent trend of massive deployment of pervasive computing technologies such as GPS and RFID on the vehicles. For example, routes and ridership data were collected with the use of smart cards and Global Positioning System (GPS) devices available on the public buses. These massive movement data collected likely contain structures and patterns that provide useful information about characteristics of the measured phenomena. The identification, analysis and comparison of such patterns will provide greater insights on human movement and behaviours within a city. These understandings will potentially contribute to a better urban management and useful information for urban transport service providers both from the private and public sectors to formulate informed decisions to gain competitive advantage or for greater public good.

In real-world practices, the use of these massive locational data, however, tend to be confined to simple tracking and mapping with GIS applications. This is mainly due to a general lack of functions in conventional GIS which is capable of analysing and model spatial and spatio-temporal data effectively.

## Objectives

Exploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing our society. In this study, I am tasked to apply appropriate Local Indicators of Spatial Association (LISA) to uncover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.

## Specific Tasks

### Geovisualisation and Analysis

-   With reference to the time intervals provided in the table below, compute the passenger trips generated by origin at the hexagon level,

    | Peak hour period             | Bus tap on time |
    |------------------------------|-----------------|
    | Weekday morning peak         | 6am to 9am      |
    | Weekday afternoon peak       | 5pm to 8pm      |
    | Weekend/holiday morning peak | 11am to 2pm     |
    | Weekend/holiday evening peak | 4pm to 7pm      |

-   Display the geographical distribution of the passenger trips by using appropriate geovisualisation methods,

-   Describe the spatial patterns revealed by the geovisualisation (not more than 200 words per visual).

### (Either) Local Indicators of Spatial Association (LISA) Analysis

-   Compute LISA of the passengers trips generate by origin at hexagon level.

-   Display the LISA maps of the passengers trips generate by origin at hexagon level. The maps should only display the significant (i.e. p-value \< 0.05)

-   With reference to the analysis results, draw statistical conclusions (not more than 200 words per visual).

### (Or) Emerging Hot Spot Analysis (EHSA)

With reference to the passenger trips by origin at the hexagon level for the four time intervals given above:

-   Perform Mann-Kendall Test by using the spatio-temporal local Gi\* values,

-   Prepared EHSA maps of the Gi\* values of the passenger trips by origin at the hexagon level. The maps should only display the significant (i.e. p-value \< 0.05).

-   With reference to the EHSA maps and data visualisation prepared, describe the spatial patterns reveled. (not more than 250 words per cluster).

## The Datasets Used

### **Apstial data**

For the purpose of this take-home exercise, *Passenger Volume by Origin Destination Bus Stops* downloaded from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html) will be used.

### **Geospatial data**

Two geospatial data will be used in this study, they are:

-   *Bus Stop Location* from LTA DataMall. It provides information about all the bus stops currently being serviced by buses, including the bus stop code (identifier) and location coordinates.

-   *hexagon*, a [hexagon](https://desktop.arcgis.com/en/arcmap/latest/tools/spatial-statistics-toolbox/h-whyhexagons.htm) layer of 250m (this distance is the perpendicular distance between the centre of the hexagon and its edges.) should be used to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA.

## Getting Started

Load in packages that will be used in this take-home exercise, they are:

-   tidyverse for non-spatial data handling,

-   sf for geospatial data handling,

-   tmap for thematic mapping,

-   sfdep for spatial dependence

-   plotly for interactive graphs and

-   knitr for creating html table.

```{r}
pacman::p_load(tidyverse, sf, tmap, sfdep, plotly, knitr)
```

## **Importing aspatial data**

The *Passenger Volume by Origin Destination Bus Stops* downloaded consists of monthly data from August to October 2023, we will import them and combine into one data frame.

```{r}
bus_aug = read_csv("data/aspatial/origin_destination_bus_202308.csv")
bus_sep = read_csv("data/aspatial/origin_destination_bus_202309.csv")
bus_oct = read_csv("data/aspatial/origin_destination_bus_202310.csv")

odbus = rbind(bus_aug, bus_sep, bus_oct)
glimpse(odbus)
```

A quick check of odbus tibble data frame shows that the values in ORIGIN_PT_CODE and DESTINATON_PT_CODE are in char data type. We will now convert these into factor data type.

```{r}
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE) 
```

```{r}
glimpse(odbus)
```

Quick check to ensure they are in factor data type.

## **Importing geospatial data**

```{r}
busstop = st_read(dsn = "data/geospatial",
                   layer = "BusStop") %>%
  st_transform(crs = 3414)
```

```{r}
st_crs(busstop)
```

> *st_crs()* function helps to check for ESPG code and coordinate system of geospatial file. Singapore's coordinate system is SVY21 with EPSG 3414, so this is correct.

## Geovisualisation and Analysis

We will now attempt to compute the passenger trips generated by origin at the hexagon level,

| Peak hour period             | Bus tap on time |
|------------------------------|-----------------|
| Weekday morning peak         | 6am to 9am      |
| Weekday afternoon peak       | 5pm to 8pm      |
| Weekend/holiday morning peak | 11am to 2pm     |
| Weekend/holiday evening peak | 4pm to 7pm      |

: The below code chunk will categorize the trips by the above peak periods using *ifelse()* conditions and derive trip numbers for every origin busstop for every month and period using *group_by()* and *summarise()*.

```{r}
odbus_periods <- odbus %>%
  mutate(period = ifelse(DAY_TYPE == "WEEKDAY" & 
                         TIME_PER_HOUR >= 6 & TIME_PER_HOUR <= 9, 
                         "Weekday morning peak",
                    ifelse(DAY_TYPE == "WEEKDAY" & 
                           TIME_PER_HOUR >= 17 & TIME_PER_HOUR <= 20,
                           "Weekday afternoon peak",
                      ifelse(DAY_TYPE == "WEEKENDS/HOLIDAY" &
                             TIME_PER_HOUR >= 11 & TIME_PER_HOUR <= 14,
                              "Weekend/holiday morning peak",
                        ifelse(DAY_TYPE == "WEEKENDS/HOLIDAY" & 
                              TIME_PER_HOUR >= 16 & TIME_PER_HOUR <= 19,
                               "Weekend/holiday evening peak",
                    "Others"))))
  ) %>%
  filter(
    period != "Others"
  ) %>%
  group_by(
    YEAR_MONTH,
    period,
    ORIGIN_PT_CODE
  ) %>%
  summarise(
    num_trips = sum(TOTAL_TRIPS)
  )
```

\[Update from Piazza [post](https://piazza.com/class/lox0v5mtchp30t/post/40)\] For the purpose analysis, we can proceed with any of the month. We will proceed with the month of August 2023.

### Analysis for August 2023 data

Below code chunk displays the number of passenger trips generated by origin.

```{r}
# Extract august data and store as separate dataframe
odbus_aug <- odbus_periods %>%
  filter(
    YEAR_MONTH == "2023-08"
  ) %>%
  pivot_wider(
    names_from = period,
    values_from = num_trips
  ) %>%
  select(2:6)

kable(odbus_aug)
```

### Creating Hexagon Grid for August 2023 data

```{r}
odbus_aug_sf <- left_join(busstop, odbus_aug, by = c("BUS_STOP_N"="ORIGIN_PT_CODE"))

odbus_aug_sf
```

We performed a left join to map `busstop` to `odbus_aug` by bus stop code.

> Referring to [reference](https://urbandatapalette.com/post/2021-08-tessellation-sf/) for creating hexagon grid, I attempted to create from `odbus_aug_sf`, but met with the following error message:
>
> ```         
> odbus_aug_sf consists of spatial points, so it cannot accept tm_fill/tm_borders/tm_polygons.
> ```

The learning point here is because `odbus_aug_sf` is a spatial point dataframe, while I will need to create a spatial polygon dataframe.

```{r}
odbus_aug_hex <- st_make_grid(
    odbus_aug_sf,
    cellsize = 500,
    square = FALSE
  ) %>%
  st_sf() %>%
  rowid_to_column("hex_id")
```

Next I will create an attribute dataframe using hex id as primary key since every hex area might contain more than one busstop.

```{r}
odbus_aug_stops <- st_join(
  odbus_aug_sf, 
  odbus_aug_hex, 
  join = st_within
  ) %>%
  st_set_geometry(NULL) %>%
  group_by(
    hex_id
  ) %>%
  summarise(
    n_busstops = n(),
    busstop_codes = str_c(BUS_STOP_N, collapse = ","),
    `Weekday morning peak` = sum(`Weekday morning peak`),
    `Weekday afternoon peak` = sum(`Weekday afternoon peak`),
    `Weekend/holiday morning peak` = sum(`Weekend/holiday morning peak`),
    `Weekend/holiday evening peak` = sum(`Weekend/holiday evening peak`)
  ) %>%
  replace(is.na(.), 0) %>%
  ungroup()
```

Finally, the spatial polygon dataframe can created by joining the `odbus_aug_stops` dataframe to `odbus_aug_hex` by "hex_id", and filter away hexagons with zero busstops.

```{r}
odbus_aug_hex <- odbus_aug_hex %>%
  left_join(odbus_aug_stops,
            by = "hex_id"
  ) %>%
  replace(is.na(.), 0)

odbus_aug_trips <- filter(odbus_aug_hex,
                       n_busstops > 0)
```

We will now plot the hexagon grid with below code chunk.

```{r}
tmap_mode("view")

odbus_aug_trips_map <- tm_basemap("CartoDB.Positron") +
  tm_shape(odbus_aug_trips) +
  tm_fill(
    col = "n_busstops",
    palette = "Reds",
    style = "cont",
    id = "hex_id",
    popup.vars = c("No. of bus stops: " = "n_busstops",
                   "Bus Stop codes: " = "busstop_codes"),
    title = "Volume of traffic"
  ) +
  tm_layout(
    legend.show = FALSE
  )

odbus_aug_trips_map
```

## Local Indicators of Spatial Association (LISA) Analysis

Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. In this case, we can use local Moran's I test to evaluate the existence of high traffic or areas that seem like outliers in the overall spatial arrangement during peak periods.

### Spatial Weight Matrix

In the code chunk below, queen method is used to derive the contiguity weights.

```{r}
wm_aug <- odbus_aug_hex %>%
  mutate(nb = st_contiguity(geometry),
         wt = st_weights(nb,
                         style = "W"),
         .before = 1)
```

> Notice that `st_weights()` provides a few arguments, they are:
>
> -   *nb*: An object created by st_contiguity() to store contiguity weight matrix.
>
> -   *style*: Default "W" for row standardized weights.

### Generation of Local Moran's I with Monte Carlo simulation

The code chunk below generates Local Moran's I for each peak period with Monte Carlo simulation.

```{r}
set.seed(1234)

#weekday morning peak
lisa_wkday_morn = wm_aug %>%
  mutate(local_moran = local_moran(
    `Weekday morning peak`,nb,wt,nsim = 99),
         .before = 1) %>%
  unnest(local_moran) %>%
  # only retain hexagons with a bus stop
  filter(n_busstops > 0)

#weekday afternoon peak
lisa_wkday_aftn = wm_aug %>%
  mutate(local_moran = local_moran(
    `Weekday afternoon peak`,nb,wt,nsim = 99),
         .before = 1) %>%
  unnest(local_moran) %>%
  # only retain hexagons with a bus stop
  filter(n_busstops > 0)

#weekend/holiday morning peak
lisa_wkend_morn = wm_aug %>%
  mutate(local_moran = local_moran(
    `Weekend/holiday morning peak`,nb,wt,nsim = 99),
         .before = 1) %>%
  unnest(local_moran) %>%
  # only retain hexagons with a bus stop
  filter(n_busstops > 0)

#weekend/holiday evening peak
lisa_wkend_evng = wm_aug %>%
  mutate(local_moran = local_moran(
    `Weekend/holiday evening peak`,nb,wt,nsim = 99),
         .before = 1) %>%
  unnest(local_moran) %>%
  # only retain hexagons with a bus stop
  filter(n_busstops > 0)
```

It is always a good practice to use `set.seed()` before performing simulation. This is to ensure that the computation is reproducible.

The output of `local_moran()` is a sf data.frame containing the columns ii, eii, var_ii, z_ii, p_ii, p_ii_sim, and p_folded_sim.

-   ii: local moran statistic

-   eii: expectation of local moran statistic; for localmoran_permthe permutation sample means

-   var_ii: variance of local moran statistic; for localmoran_permthe permutation sample standard deviations

-   z_ii: standard deviate of local moran statistic; for localmoran_perm based on permutation sample means and standard deviations

-   p_ii: p-value of local moran statistic using pnorm(); for localmoran_perm using standard deviatse based on permutation sample means and standard deviations

-   p_ii_sim: For `localmoran_perm()`, `rank()` and `punif()` of observed statistic rank for \[0, 1\] p-values using `alternative=`

-   p_folded_sim: the simulation folded \[0, 0.5\] range ranked p-value based on [crand.py](https://github.com/pysal/esda/blob/4a63e0b5df1e754b17b5f1205b8cadcbecc5e061/esda/crand.py#L211-L213) of pysal

-   skewness: For `localmoran_perm`, the output of e1071::skewness() for the permutation samples underlying the standard deviates

-   kurtosis: For `localmoran_perm`, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates.

-   `unnest()` of **tidyr** package is used to expand a list-column containing data frames into rows and columns.

### Visualising local Moran's I and p-value

Code chunk below will use `tmap` functions to prepare choropleth maps by using local Moran's I and its p-value.

```{r}
tmap_mode("plot")

map1 <- tm_shape(lisa_wkday_morn) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Weekday morning peak",
            main.title.size = 0.8)

map2 <- tm_shape(lisa_wkday_morn) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

map3 <- tm_shape(lisa_wkday_aftn) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Weekday afternoon peak",
            main.title.size = 0.8)

map4 <- tm_shape(lisa_wkday_aftn) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

map5 <- tm_shape(lisa_wkend_morn) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Weekend/holiday morning peak",
            main.title.size = 0.8)

map6 <- tm_shape(lisa_wkend_morn) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

map7 <- tm_shape(lisa_wkend_evng) +
  tm_fill("ii") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "local Moran's I of Weekend/holiday evening peak",
            main.title.size = 0.8)

map8 <- tm_shape(lisa_wkend_evng) +
  tm_fill("p_ii_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of local Moran's I",
            main.title.size = 0.8)

tmap_arrange(map1, map2, map3, map4, map5, map6, map7, map8, ncol = 2)
```

We can observe several clusters since there are areas with high and positive Local Moran's I value. For weekdays and weekends/holidays, we can see that there are more clusters in the morning peak compared to afternoon and evenings.

### Visualising LISA maps (weekday morning peak)

LISA map is a categorical map which shows outliers and clusters. There are two types of outliers: High-Low and Low-High outliers. Similarly, there are two types of clustes: High-High and Low-Low clusters. LISA map can be interpreted as a combination of Local Moran's I of geographical areas and their respective p-values.

In LISA sf dataframe, we will find three fields contained *mean*, *median* and *pysal*. In general, classification in *mean* will be used as shown in code chunk below. We will first look at the LISA map for weekday morning peak period.

```{r}
lisa_sig1 <- lisa_wkday_morn  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")
tm_shape(lisa_wkday_morn) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig1) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

We can observe that there are several High-High clusters in the north, south, east and west areas, presumably in the higher-populated residential areas like Sembawang, Jurong East, Tiong Bahru, Hougang and Tampines etc. High-High clusters are likely of spatial autocorrelation, where attributes are likely to correlate positively with attributes of neighbours.

There are sparse yet connected Low-High outliers which suggest the area's attributes have a negative autocorrelation with its neighbour's attributes. These are also likely areas with less passenger volume in weekday mornings, as they are less densely populated or industrial areas such as Tuas and Seletar, and affluent areas such as Bukit Timah where residents are more likely to travel by private modes of transport.

### Visualising LISA maps (weekday afternoon peak)

```{r}
lisa_sig2 <- lisa_wkday_aftn  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")
tm_shape(lisa_wkday_aftn) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig2) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

In terms of Low-High outliers and High-High clusters, we observe them to be similar as what we saw from weekday morning peak periods, except that the weekday afternoon's High-High clusters look smaller. The explanation in similarity is that the trip volume and attributes of the areas are highly similar as these are the periods when most adults and students head to and fro their workplace or institutions. For the difference between morning and afternoon's High-High clusters, this could be due to the differences in students' and working adults' end times, which have a high variance compared to the start times of students and working adults, which have a much smaller variance.

### Visualising LISA maps (weekend/holidays morning and evening peaks)

We will plot the weekend/holiday morning and evening peaks in quick succession to spot any differences.

```{r}
lisa_sig3 <- lisa_wkend_morn  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")
tm_shape(lisa_wkend_morn) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig3) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

```{r}
lisa_sig4 <- lisa_wkend_evng  %>%
  filter(p_ii_sim < 0.05)
tmap_mode("plot")
tm_shape(lisa_wkend_evng) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig4) +
  tm_fill("mean") + 
  tm_borders(alpha = 0.4)
```

Similar to the difference between weekdays' morning and afternoon peak periods, weekends' morning and evening peak periods exhibit the same difference in that the High-High clusters are less clustered. This can similarly be attributed to the behaviours of the population, where morning periods are when residents are out and about, and their end times can vary hugely within the day.

## Conclusion and Thoughts

We have explored mainly the August 2023 passenger travel data and visualised passenger travel patterns from the data. While we have gained some insights from the patterns revealed, we can do more with additional dimensions of data:

-   The data does not reveal information on transfers. It might be useful to show origin_pt_code which occur within a proxy (say, 5mins) duration after ending at destination_pt_code as this would show a point of transfer. Data on transfers can be useful as it will offer insights on potential improvement and optimization on bus routes or even demand for new routes. One limitation of this data, though, is that it might require the collation of ezlink card's CAN ID, which might be difficult to obtain given the potential data security and privacy issue.

-   The data does not reveal information on bus routes or bus service number. This will allow us to differentiate between the different bus services and might offer insights into the more popular or congested bus routes. High congestion might be due to lack in bus arrival frequency, or that the bus route can be optimized or to have other less congested bus services to route and overlap the route.
